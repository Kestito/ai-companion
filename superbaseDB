-- Connect to Supabase using the credentials:
-- URL: https://aubulhjfeszmsheonmpy.supabase.co
-- Key: [your_supabase_key]

-- Enable necessary extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create schema for our application
CREATE SCHEMA IF NOT EXISTS information_search;

-- Set the search path
SET search_path TO information_search, public;

-- Documents table with summary fields
CREATE TABLE IF NOT EXISTS documents (
    id UUID PRIMARY KEY DEFAULT extensions.uuid_generate_v4(),
    url TEXT NOT NULL,
    title TEXT NOT NULL,
    content_hash TEXT UNIQUE NOT NULL,
    language TEXT NOT NULL,
    source_type TEXT NOT NULL,
    summary TEXT, -- Added summary field for document-level summary
    metadata JSONB NOT NULL DEFAULT '{}'::jsonb,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Document chunks table with enhanced metadata
CREATE TABLE IF NOT EXISTS document_chunks (
    id UUID PRIMARY KEY DEFAULT extensions.uuid_generate_v4(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    qdrant_point_id TEXT NOT NULL,
    chunk_number INTEGER NOT NULL,
    chunk_content TEXT NOT NULL,
    chunk_hash TEXT NOT NULL,
    title TEXT NOT NULL, -- Added explicit title field
    summary TEXT NOT NULL, -- Added explicit summary field
    semantic_context TEXT, -- For contextual information
    metadata JSONB NOT NULL DEFAULT '{}'::jsonb,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE(document_id, chunk_number)
);

-- Search queries
CREATE TABLE search_queries (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    query_text TEXT NOT NULL,
    qdrant_query_vector_hash VARCHAR(64),
    search_type VARCHAR(50) NOT NULL,
    similarity_metric VARCHAR(20) NOT NULL,
    filters JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    execution_time_ms INTEGER,
    metadata JSONB
);

-- Search results
CREATE TABLE search_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    query_id UUID NOT NULL,
    document_id UUID NOT NULL,
    chunk_id UUID,
    qdrant_score FLOAT NOT NULL,
    rank INTEGER NOT NULL,
    relevance_score FLOAT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT fk_query FOREIGN KEY(query_id) REFERENCES search_queries(id) ON DELETE CASCADE,
    CONSTRAINT fk_document FOREIGN KEY(document_id) REFERENCES documents(id) ON DELETE CASCADE,
    CONSTRAINT fk_chunk FOREIGN KEY(chunk_id) REFERENCES document_chunks(id) ON DELETE SET NULL
);

-- Create indexes for efficient querying
CREATE INDEX IF NOT EXISTS idx_documents_content_hash ON documents(content_hash);
CREATE INDEX IF NOT EXISTS idx_documents_source_type ON documents(source_type);
CREATE INDEX IF NOT EXISTS idx_documents_language ON documents(language);
CREATE INDEX IF NOT EXISTS idx_document_chunks_document_id ON document_chunks(document_id);
CREATE INDEX IF NOT EXISTS idx_document_chunks_qdrant_point_id ON document_chunks(qdrant_point_id);
CREATE INDEX IF NOT EXISTS idx_document_chunks_title ON document_chunks USING gin (to_tsvector('english', title));
CREATE INDEX IF NOT EXISTS idx_document_chunks_summary ON document_chunks USING gin (to_tsvector('english', summary));

-- Add triggers for updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_documents_updated_at
    BEFORE UPDATE ON documents
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_document_chunks_updated_at
    BEFORE UPDATE ON document_chunks
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- Create a view for document summaries with their chunks
CREATE OR REPLACE VIEW v_document_summaries AS
SELECT 
    d.id as document_id,
    d.title as document_title,
    d.summary as document_summary,
    d.url,
    d.source_type,
    d.language,
    json_agg(json_build_object(
        'chunk_number', dc.chunk_number,
        'title', dc.title,
        'summary', dc.summary,
        'semantic_context', dc.semantic_context
    ) ORDER BY dc.chunk_number) as chunks
FROM documents d
LEFT JOIN document_chunks dc ON d.id = dc.document_id
GROUP BY d.id, d.title, d.summary, d.url, d.source_type, d.language;

-- Create RLS policies
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE document_chunks ENABLE ROW LEVEL SECURITY;
ALTER TABLE search_queries ENABLE ROW LEVEL SECURITY;
ALTER TABLE search_results ENABLE ROW LEVEL SECURITY;

-- Create policies
CREATE POLICY "Allow public read access to documents"
    ON documents FOR SELECT
    TO authenticated
    USING (true);

CREATE POLICY "Allow public read access to document_chunks"
    ON document_chunks FOR SELECT
    TO authenticated
    USING (true);

CREATE POLICY "Enable read access for all users" ON search_queries
    FOR SELECT USING (true);

CREATE POLICY "Enable read access for all users" ON search_results
    FOR SELECT USING (true);

-- Create indexes
CREATE INDEX idx_search_queries_created_at ON search_queries(created_at);
CREATE INDEX idx_search_results_query_id ON search_results(query_id);
CREATE INDEX idx_search_results_document_id ON search_results(document_id);

-- Create views
CREATE VIEW v_search_performance AS
SELECT 
    sq.id as query_id,
    sq.query_text,
    sq.search_type,
    sq.similarity_metric,
    sq.execution_time_ms,
    COUNT(sr.id) as result_count,
    AVG(sr.qdrant_score) as avg_similarity,
    AVG(sr.relevance_score) as avg_relevance
FROM search_queries sq
LEFT JOIN search_results sr ON sq.id = sr.query_id
GROUP BY sq.id, sq.query_text, sq.search_type, sq.similarity_metric, sq.execution_time_ms;