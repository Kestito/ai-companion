-- Connect to Supabase using the credentials:
-- URL: https://aubulhjfeszmsheonmpy.supabase.co
-- Key: [your_supabase_key]

-- Enable necessary extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create schema for our application
CREATE SCHEMA IF NOT EXISTS information_search;

-- Set the search path
SET search_path TO information_search, public;

-- Documents table with summary fields
CREATE TABLE IF NOT EXISTS documents (
    id UUID PRIMARY KEY DEFAULT extensions.uuid_generate_v4(),
    url TEXT NOT NULL,
    title TEXT NOT NULL,
    content_hash TEXT UNIQUE NOT NULL,
    language TEXT NOT NULL,
    source_type TEXT NOT NULL,
    summary TEXT, -- Added summary field for document-level summary
    metadata JSONB NOT NULL DEFAULT '{}'::jsonb,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Document chunks table with enhanced metadata
CREATE TABLE IF NOT EXISTS document_chunks (
    id UUID PRIMARY KEY DEFAULT extensions.uuid_generate_v4(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    qdrant_point_id TEXT NOT NULL,
    chunk_number INTEGER NOT NULL,
    chunk_content TEXT NOT NULL,
    chunk_hash TEXT NOT NULL,
    title TEXT NOT NULL, -- Added explicit title field
    summary TEXT NOT NULL, -- Added explicit summary field
    semantic_context TEXT, -- For contextual information
    metadata JSONB NOT NULL DEFAULT '{}'::jsonb,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE(document_id, chunk_number)
);

-- Search queries
CREATE TABLE search_queries (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    query_text TEXT NOT NULL,
    qdrant_query_vector_hash VARCHAR(64),
    search_type VARCHAR(50) NOT NULL,
    similarity_metric VARCHAR(20) NOT NULL,
    filters JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    execution_time_ms INTEGER,
    metadata JSONB
);

-- Search results
CREATE TABLE search_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    query_id UUID NOT NULL,
    document_id UUID NOT NULL,
    chunk_id UUID,
    qdrant_score FLOAT NOT NULL,
    rank INTEGER NOT NULL,
    relevance_score FLOAT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT fk_query FOREIGN KEY(query_id) REFERENCES search_queries(id) ON DELETE CASCADE,
    CONSTRAINT fk_document FOREIGN KEY(document_id) REFERENCES documents(id) ON DELETE CASCADE,
    CONSTRAINT fk_chunk FOREIGN KEY(chunk_id) REFERENCES document_chunks(id) ON DELETE SET NULL
);

-- Create indexes for efficient querying
CREATE INDEX IF NOT EXISTS idx_documents_content_hash ON documents(content_hash);
CREATE INDEX IF NOT EXISTS idx_documents_source_type ON documents(source_type);
CREATE INDEX IF NOT EXISTS idx_documents_language ON documents(language);
CREATE INDEX IF NOT EXISTS idx_document_chunks_document_id ON document_chunks(document_id);
CREATE INDEX IF NOT EXISTS idx_document_chunks_qdrant_point_id ON document_chunks(qdrant_point_id);
CREATE INDEX IF NOT EXISTS idx_document_chunks_title ON document_chunks USING gin (to_tsvector('english', title));
CREATE INDEX IF NOT EXISTS idx_document_chunks_summary ON document_chunks USING gin (to_tsvector('english', summary));

-- Add triggers for updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_documents_updated_at
    BEFORE UPDATE ON documents
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_document_chunks_updated_at
    BEFORE UPDATE ON document_chunks
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- Create a view for document summaries with their chunks
CREATE OR REPLACE VIEW v_document_summaries AS
SELECT 
    d.id as document_id,
    d.title as document_title,
    d.summary as document_summary,
    d.url,
    d.source_type,
    d.language,
    json_agg(json_build_object(
        'chunk_number', dc.chunk_number,
        'title', dc.title,
        'summary', dc.summary,
        'semantic_context', dc.semantic_context
    ) ORDER BY dc.chunk_number) as chunks
FROM documents d
LEFT JOIN document_chunks dc ON d.id = dc.document_id
GROUP BY d.id, d.title, d.summary, d.url, d.source_type, d.language;

-- Create RLS policies
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE document_chunks ENABLE ROW LEVEL SECURITY;
ALTER TABLE search_queries ENABLE ROW LEVEL SECURITY;
ALTER TABLE search_results ENABLE ROW LEVEL SECURITY;

-- Create policies
CREATE POLICY "Allow public read access to documents"
    ON documents FOR SELECT
    TO authenticated
    USING (true);

CREATE POLICY "Allow public read access to document_chunks"
    ON document_chunks FOR SELECT
    TO authenticated
    USING (true);

CREATE POLICY "Enable read access for all users" ON search_queries
    FOR SELECT USING (true);

CREATE POLICY "Enable read access for all users" ON search_results
    FOR SELECT USING (true);

-- Create indexes
CREATE INDEX idx_search_queries_created_at ON search_queries(created_at);
CREATE INDEX idx_search_results_query_id ON search_results(query_id);
CREATE INDEX idx_search_results_document_id ON search_results(document_id);

-- Create views
CREATE VIEW v_search_performance AS
SELECT 
    sq.id as query_id,
    sq.query_text,
    sq.search_type,
    sq.similarity_metric,
    sq.execution_time_ms,
    COUNT(sr.id) as result_count,
    AVG(sr.qdrant_score) as avg_similarity,
    AVG(sr.relevance_score) as avg_relevance
FROM search_queries sq
LEFT JOIN search_results sr ON sq.id = sr.query_id
GROUP BY sq.id, sq.query_text, sq.search_type, sq.similarity_metric, sq.execution_time_ms;

-- First, let's drop the existing functions to start fresh
DROP FUNCTION IF EXISTS public.search_documents(TEXT, INTEGER, BOOLEAN, FLOAT);
DROP FUNCTION IF EXISTS public.search_documents(TEXT, INTEGER);
DROP FUNCTION IF EXISTS public.search_documents(TEXT);
DROP FUNCTION IF EXISTS public.test_search_function(TEXT);
DROP FUNCTION IF EXISTS public.test_search_function();

-- Create a very simple search function that we KNOW will work
CREATE OR REPLACE FUNCTION public.search_documents(
    query_text TEXT,
    limit_val INTEGER DEFAULT 10
) 
RETURNS TABLE (
    id UUID,
    document_id UUID,
    title TEXT,
    chunk_content TEXT,
    rank REAL,
    url TEXT,
    source_type TEXT
)
LANGUAGE SQL
SECURITY DEFINER
AS $$
    -- Super simple implementation - just use ILIKE
    SELECT 
        dc.id,
        dc.document_id,
        dc.title,
        dc.chunk_content,
        1.0 as rank,
        d.url,
        d.source_type
    FROM 
        public.document_chunks dc
    JOIN 
        public.documents d ON dc.document_id = d.id
    WHERE 
        dc.chunk_content ILIKE '%' || query_text || '%'
        OR dc.title ILIKE '%' || query_text || '%'
    LIMIT limit_val;
$$;

-- Grant execute permissions
GRANT EXECUTE ON FUNCTION public.search_documents(TEXT, INTEGER) TO public;

-- Create a very simple test function
CREATE OR REPLACE FUNCTION public.test_search_function(
    test_query TEXT DEFAULT 'POLA'
)
RETURNS TEXT
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
    result_count INTEGER;
BEGIN
    -- Count the results directly
    SELECT COUNT(*) INTO result_count
    FROM public.search_documents(test_query, 10);
    
    -- Return simple result message
    IF result_count > 0 THEN
        RETURN 'SUCCESS - Found ' || result_count || ' results for query "' || test_query || '"';
    ELSE
        RETURN 'WARNING - No results found for query "' || test_query || '"';
    END IF;
EXCEPTION WHEN OTHERS THEN
    RETURN 'ERROR - ' || SQLERRM;
END;
$$;

-- Grant execute permissions
GRANT EXECUTE ON FUNCTION public.test_search_function(TEXT) TO public;